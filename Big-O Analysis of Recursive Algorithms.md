Related to [[Big O Notation]]
- ## Develop a reccurence relationship
	- Express the run time for the problem size $n$ in tersm of sub problems and any extra work needed to combine the sub problems
	- The standard form for this relationship is $$T(n)=aT\left( \frac{n}{b} \right)+O(n^{d})$$
	- Example: Integer multiplication
		- $n$ is the number of digits of the second mulitplicand
		- Divide an operation like 1234\*5678 into $(12*100+34)(56*100+78)=100^{2}*12*56+100*12*78+100*34*56+34*78$
		- This means that each recursion divides $n$ by 2, and the $b$ term is 2.
		- This results in $a=4$ and $d=1$
			- The O(n) term is the addition
		- $T(n)=4*T\left( \frac{n}{2} \right)+O(n)$
- ## Use the master method to solve the relationship
	- Recurrence Relationship Form:$$T(n)=aT\left( \frac{n}{b} \right)+O(n^{d})$$
	- Case 1: $a=b^{d},\ T(n)=(n^{d}\log n)$
	- Case 2: $a<b^{d},\,T(n)=O(n^{d})$
	- Case 3: $a>b^{d},\,T(n)=O(n^{\log_{b}a})$
	- These parameters describe
		- $a$: Number of subproblems
		- $b$: Factor by which input size shirnks upon recursion
		- $d:$ need to do $n^d$ work to create all subproblems and combine their solutions
		- Note: $\frac{n}{b}$ can be taken as the floor or ceiling and this works just fine
	- Above multiplication example has $b^{d}=2^{1}$
		- This is a case 3 algorithm with $$T(n)=O(n^{\log_{2}4}=O(n^{2}))$$
- ## Karatsuba Algorithm: Improved Multiplication
	- $ab*cd=(a+b)(c+d)-ac-bd$
	- $=ad+bc$
	- Is faster than traditional algorithm because it reduces the number of subproblems to 3 rather than 4
		- $T(n)=3T\left( \frac{n}{2} \right)+O(n)$
- ## Binary Search Analysis
	- Divides into 2 sub problems $a=1$
	- Divides n by 2 $b=2$
	- Need to do constant work to create and combine subproblems $d=0$
	- $b^{d}=1$
	- Case 1 algorithm with 
		- $T(n)=T\left( \frac{n}{2} \right)+O(1)=O(1*\log n)$
For class #data-structures
